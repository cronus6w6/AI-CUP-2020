{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train",
      "provenance": [],
      "mount_file_id": "1Bt9EThnilNr6U63C7NcugtRLsbUK3Hbp",
      "authorship_tag": "ABX9TyO2KuzYrh1TO/fQJUzXvNbl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cronus6w6/AI-CUP-2020/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV38Huk1bJ3j"
      },
      "source": [
        "#準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1emH_WfFbTrd"
      },
      "source": [
        "##安裝及引入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv6OM6HsjnQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adb4276-11cc-4c70-9434-ea7751ec6558"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvBfSAjxla8s"
      },
      "source": [
        "from transformers import *\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import shutil\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-tiQ7L7bfNd"
      },
      "source": [
        "## 參數調整"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnXwetpsblaM"
      },
      "source": [
        "train_data_path = \"trainset.csv\"\r\n",
        "LABELS = [\"THEORETICAL\", \"ENGINEERING\", \"EMPIRICAL\", \"OTHERS\"]\r\n",
        "Epochs = 5\r\n",
        "lr = 1e-5\r\n",
        "thrld = [0.35, 0.3, 0.25, 0.35]\r\n",
        "positive_weights = [1., 1., 1.75, 7.5]\r\n",
        "[1., 1., 1.75, 7.5]\r\n",
        "dropout = 0.2\r\n",
        "hidden_unit = 64\r\n",
        "# seed = random.randint(0, 100000)\r\n",
        "seed = 29231"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6iYwXe6cK8S"
      },
      "source": [
        "##初始化設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxRsQHqxcKMn"
      },
      "source": [
        "torch.manual_seed(seed)\r\n",
        "torch.cuda.manual_seed(seed)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuUKp1WVcgVL"
      },
      "source": [
        "#資料處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MACubcR9c6bB"
      },
      "source": [
        "宣告資料集類別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCdjlfRWclAx"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\r\n",
        "class _DataSet(torch.utils.data.Dataset):\r\n",
        "  def __init__(self, inp_data: pd.DataFrame):\r\n",
        "    title_indices = []\r\n",
        "    title_segments = []\r\n",
        "    abstract_indices = []\r\n",
        "    abstract_segments = []\r\n",
        "    self.return_labels = \"Classifications\" in inp_data.columns\r\n",
        "    if self.return_labels:\r\n",
        "      labels = []\r\n",
        "    for _, row in tqdm(inp_data.iterrows(), total=len(inp_data)):\r\n",
        "      title_index = tokenizer.encode(row.Title, max_length=512, padding=\"max_length\")\r\n",
        "      abstract_index = tokenizer.encode(row.Abstract, max_length=512, padding=\"max_length\", truncation=True)\r\n",
        "      title_indices.append(title_index)\r\n",
        "      abstract_indices.append(abstract_index)\r\n",
        "      if self.return_labels:\r\n",
        "        labels.append(list(map(lambda l: 1 if l in row.Classifications.split(\" \") else 0, LABELS)))\r\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32, device=device)\r\n",
        "    self.title_indices = torch.tensor(title_indices, dtype=torch.long, device=device)\r\n",
        "    self.title_segments = torch.zeros(self.title_indices.size(), dtype=torch.long, device=device)\r\n",
        "    self.abstract_indices = torch.tensor(abstract_indices, dtype=torch.long, device=device)\r\n",
        "    self.abstract_segments = torch.zeros(self.abstract_indices.size(), dtype=torch.long, device=device)\r\n",
        "  def __getitem__(self, index):\r\n",
        "    if self.return_labels:\r\n",
        "      return ({\r\n",
        "        \"title_indices\": self.title_indices[index],\r\n",
        "        \"title_segments\": self.title_segments[index],\r\n",
        "        \"abstract_indices\": self.abstract_indices[index],\r\n",
        "        \"abstract_segments\": self.abstract_segments[index]\r\n",
        "      }, self.labels[index])\r\n",
        "    return {\r\n",
        "      \"title_indices\": self.title_indices[index],\r\n",
        "      \"title_segments\": self.title_segments[index],\r\n",
        "      \"abstract_indices\": self.abstract_indices[index],\r\n",
        "      \"abstract_segments\": self.abstract_segments[index]\r\n",
        "    }\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.title_indices)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm-AbUIQdBic"
      },
      "source": [
        "切詞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zVr4V7ccfj-",
        "outputId": "c7bf61d2-2d3b-40ce-98e7-2712203e36f1"
      },
      "source": [
        "trainset = pd.read_csv(train_data_path)\r\n",
        "trainset.Abstract = trainset.Abstract.str.replace(\"\\$\\$\\$\", \" \")\r\n",
        "train_data = _DataSet(trainset.iloc[:6300])\r\n",
        "val_data = _DataSet(trainset.iloc[6300:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6300/6300 [00:13<00:00, 457.33it/s]\n",
            "100%|██████████| 700/700 [00:00<00:00, 851.84it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajefaMxbdsR3"
      },
      "source": [
        "製作batch loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LYrWhBXdqGX"
      },
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(train_data, 5)\r\n",
        "val_data_loader = torch.utils.data.DataLoader(val_data, 5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008BWfGcd0aK"
      },
      "source": [
        "# 模型製作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8OWm_POd4MQ"
      },
      "source": [
        "class MultiClassificationModel(nn.Module):\r\n",
        "  def __init__(self, encoder):\r\n",
        "    super(MultiClassificationModel, self).__init__()\r\n",
        "    self.encoder = encoder\r\n",
        "    self.classifier = nn.Sequential(\r\n",
        "        nn.Linear(768 * 2, hidden_unit),\r\n",
        "        nn.GELU(),\r\n",
        "        nn.Dropout(dropout),\r\n",
        "        nn.Linear(hidden_unit, 4)\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, title_indices, title_segments, abstract_indices, abstract_segments):\r\n",
        "    title_embs = self.encoder(title_indices, token_type_ids=title_segments)[0][:, 0, :]\r\n",
        "    abstract_embs = self.encoder(abstract_indices, token_type_ids=abstract_segments)[0][:, 0, :]\r\n",
        "    \r\n",
        "    embs = torch.cat([title_embs, abstract_embs], 1)\r\n",
        "    result = self.classifier(embs)\r\n",
        "    return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tSwMqeseI8A",
        "outputId": "09e7fc31-1bfa-42ea-8fca-a8ccbfa9be8d"
      },
      "source": [
        "scibert = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\r\n",
        "model = MultiClassificationModel(scibert)\r\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassificationModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1536, out_features=64, bias=True)\n",
              "    (1): GELU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=64, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tshAUf1ueUds"
      },
      "source": [
        "#訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_dWNL35hBM8"
      },
      "source": [
        "F1 Score 計算函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfuqga_vhArv"
      },
      "source": [
        "def micro_f1_score(pred, label):\r\n",
        "    \r\n",
        "    TP = torch.mul(pred, label)[0]\r\n",
        "    FP = (torch.mul(pred, (label-1)) != 0)[0]\r\n",
        "    FN = (torch.mul(pred-1, label) != 0)[0]\r\n",
        "    \r\n",
        "    precision = TP.sum() / (TP.sum() + FP.sum())\r\n",
        "    recall = TP.sum() / (TP.sum() + FN.sum())\r\n",
        "    \r\n",
        "    f1 = 2 * precision * recall / (precision + recall)\r\n",
        "    \r\n",
        "    return f1, TP, FP, FN"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIfIC8MeY6V"
      },
      "source": [
        "pos_weight = torch.FloatTensor(positive_weights).to(device)\r\n",
        "total_step = len(train_data_loader) * Epochs\r\n",
        "warmup_step = total_step // 2\r\n",
        "\r\n",
        "optimizer =  AdamW(model.parameters(), lr=lr, correct_bias=False)\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps= warmup_step, num_training_steps=total_step)\r\n",
        "best_f1 = -1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vPzaGZdeoOc",
        "outputId": "dbcd7852-ac4e-494b-d974-e3d2cba8cdd1"
      },
      "source": [
        "for epoch in range(Epochs):\r\n",
        "  print(f\"Epoch {epoch}:\")\r\n",
        "  \r\n",
        "  # Train\r\n",
        "  model = model.train()\r\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\r\n",
        "  thrld = np.array(thrld)\r\n",
        "  total_loss = 0.0\r\n",
        "  train_metric = { \"TP\":np.zeros(4), \"FP\":np.zeros(4), \"FN\":np.zeros(4), \"F1\":[] }\r\n",
        "  thrld_ten = torch.from_numpy(thrld).float().to(device)\r\n",
        "  train_metric[\"TP\"] = torch.from_numpy(train_metric[\"TP\"]).float().to(device)\r\n",
        "  train_metric[\"FP\"] = torch.from_numpy(train_metric[\"FP\"]).float().to(device)\r\n",
        "  train_metric[\"FN\"] = torch.from_numpy(train_metric[\"FN\"]).float().to(device)\r\n",
        "\r\n",
        "  optimizer.zero_grad()\r\n",
        "  for features, labels in tqdm(train_data_loader, total=len(train_data_loader), desc=\"Training...\"):\r\n",
        "    optimizer.step()\r\n",
        "    scheduler.step()\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    result = model(**features)\r\n",
        "    l = criterion(result, labels)\r\n",
        "    total_loss += l.item()\r\n",
        "    l.backward()\r\n",
        "    \r\n",
        "    result = torch.sigmoid(result)\r\n",
        "    pred = (result > thrld_ten.expand(labels.size())).float()\r\n",
        "    f1, tp, fp, fn = micro_f1_score(pred, labels)\r\n",
        "\r\n",
        "    train_metric[\"F1\"].append(f1)\r\n",
        "    train_metric[\"TP\"] += tp.float()\r\n",
        "    train_metric[\"FP\"] += fp.float()\r\n",
        "    train_metric[\"FN\"] += fn.float()\r\n",
        "\r\n",
        "  optimizer.step()\r\n",
        "  scheduler.step()\r\n",
        "\r\n",
        "  train_precision_all = train_metric[\"TP\"].sum().item() / (train_metric[\"TP\"].sum().item() + train_metric[\"FP\"].sum().item())\r\n",
        "  train_recall_all = train_metric[\"TP\"].sum().item() / (train_metric[\"TP\"].sum().item() + train_metric[\"FN\"].sum().item())\r\n",
        "  train_micro_f1 = (2 * train_precision_all * train_recall_all) / (train_precision_all + train_recall_all)\r\n",
        "\r\n",
        "  avg_loss = total_loss / len(train_data_loader)\r\n",
        "\r\n",
        "  print(\"Train Loss:{}\\tmicro_f1:{}\".format(avg_loss, train_micro_f1))\r\n",
        "  print(\"micro_f1s:\", end=\"\")\r\n",
        "  for i in range(4):\r\n",
        "    precision = train_metric[\"TP\"][i].item() / (train_metric[\"TP\"][i].item()+train_metric[\"FP\"][i].item()+1e-10)\r\n",
        "    recall = train_metric[\"TP\"][i].item() / (train_metric[\"TP\"][i].item()+train_metric[\"FN\"][i].item()+1e-10)\r\n",
        "    print(\"{}\".format(2*precision*recall / (precision+recall+1e-10)), end=\"\\t\")\r\n",
        "\r\n",
        "  print(\"\")\r\n",
        "\r\n",
        "  #Evaluation\r\n",
        "  model = model.eval()\r\n",
        "  criterion = nn.BCEWithLogitsLoss()\r\n",
        "  \r\n",
        "  dev_loss = 0.0\r\n",
        "  dev_metric = { \"TP\":np.zeros(4), \"FP\":np.zeros(4), \"FN\":np.zeros(4), \"F1\":[] }\r\n",
        "  dev_metric[\"TP\"] = torch.from_numpy(dev_metric[\"TP\"]).float().to(device)\r\n",
        "  dev_metric[\"FP\"] = torch.from_numpy(dev_metric[\"FP\"]).float().to(device)\r\n",
        "  dev_metric[\"FN\"] = torch.from_numpy(dev_metric[\"FN\"]).float().to(device)\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    for features, labels in tqdm(val_data_loader, total=len(val_data_loader), desc=\"Training...\"):\r\n",
        "      optimizer.step()\r\n",
        "      scheduler.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "\r\n",
        "      result = model(**features)\r\n",
        "      l = criterion(result, labels)\r\n",
        "      dev_loss += l\r\n",
        "      \r\n",
        "      result = torch.sigmoid(result)\r\n",
        "\r\n",
        "      pred = (result > thrld_ten.expand(labels.size())).float()\r\n",
        "      f1, tp, fp, fn = micro_f1_score(pred, labels)\r\n",
        "\r\n",
        "      dev_metric[\"F1\"].append(f1)\r\n",
        "      dev_metric[\"TP\"] += tp.float()\r\n",
        "      dev_metric[\"FP\"] += fp.float()\r\n",
        "      dev_metric[\"FN\"] += fn.float()\r\n",
        "\r\n",
        "\r\n",
        "  dev_precision_all = dev_metric[\"TP\"].sum().item() / (dev_metric[\"TP\"].sum().item() + dev_metric[\"FP\"].sum().item())\r\n",
        "  dev_recall_all = dev_metric[\"TP\"].sum().item() / (dev_metric[\"TP\"].sum().item() + dev_metric[\"FN\"].sum().item())\r\n",
        "  dev_micro_f1 = (2 * dev_precision_all * dev_recall_all) / (dev_precision_all + dev_recall_all)\r\n",
        "\r\n",
        "  avg_loss = dev_loss / len(train_data_loader)\r\n",
        "\r\n",
        "  print(\"Train Loss:{}\\tmicro_f1:{}\".format(avg_loss, dev_micro_f1))\r\n",
        "  print(\"micro_f1s:\", end=\"\")\r\n",
        "  for i in range(4):\r\n",
        "    precision = dev_metric[\"TP\"][i].item() / (dev_metric[\"TP\"][i].item()+dev_metric[\"FP\"][i].item()+1e-10)\r\n",
        "    recall = dev_metric[\"TP\"][i].item() / (dev_metric[\"TP\"][i].item()+dev_metric[\"FN\"][i].item()+1e-10)\r\n",
        "    print(\"{}\".format(2*precision*recall / (precision+recall+1e-10)), end=\"\\t\")\r\n",
        "\r\n",
        "  print(\"\")\r\n",
        "  if dev_micro_f1 > best_f1:\r\n",
        "    best_f1 = dev_micro_f1\r\n",
        "print(\"Best F1: {}\".format(best_f1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rTraining...:   0%|          | 0/1260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 1260/1260 [22:59<00:00,  1.09s/it]\n",
            "Training...:   0%|          | 0/140 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.705875653170404\tmicro_f1:0.5811084514822317\n",
            "micro_f1s:0.6356321838635669\t0.6701846965252891\t0.47466007412931216\t0.0674157303034213\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 140/140 [00:55<00:00,  2.51it/s]\n",
            "Training...:   0%|          | 0/1260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.05864159017801285\tmicro_f1:0.6284658040665435\n",
            "micro_f1s:0.7053140096154963\t0.6494845360375917\t0.5263157894249769\t0.30769230765887573\t\n",
            "Epoch 1:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 1260/1260 [22:59<00:00,  1.10s/it]\n",
            "Training...:   0%|          | 0/140 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.5688511617481709\tmicro_f1:0.6554698138901498\n",
            "micro_f1s:0.7253968253470378\t0.722255548842971\t0.5528330780594093\t0.2774566473642421\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 140/140 [00:55<00:00,  2.50it/s]\n",
            "Training...:   0%|          | 0/1260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.04891800880432129\tmicro_f1:0.715261958997722\n",
            "micro_f1s:0.7950310558500676\t0.7338129495895451\t0.6495726495242018\t0.3636363635979339\t\n",
            "Epoch 2:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 1260/1260 [22:58<00:00,  1.09s/it]\n",
            "Training...:   0%|          | 0/140 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.5047746725676079\tmicro_f1:0.6874847523786289\n",
            "micro_f1s:0.7470881863060158\t0.7498392282474031\t0.5852036574792397\t0.35971223017558096\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 140/140 [00:55<00:00,  2.50it/s]\n",
            "Training...:   0%|          | 0/1260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.0486801415681839\tmicro_f1:0.7\n",
            "micro_f1s:0.7874999999493985\t0.7194244603809327\t0.6440677965618931\t0.26086956518109644\t\n",
            "Epoch 3:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 1260/1260 [22:59<00:00,  1.09s/it]\n",
            "Training...:   0%|          | 0/140 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.4374605437238065\tmicro_f1:0.727691127588852\n",
            "micro_f1s:0.7817258882747614\t0.784366576770341\t0.6239999999548678\t0.46666666662261114\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 140/140 [00:55<00:00,  2.50it/s]\n",
            "Training...:   0%|          | 0/1260 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.046231459826231\tmicro_f1:0.7075471698113208\n",
            "micro_f1s:0.7638888888378376\t0.7272727272222601\t0.6722689075148648\t0.3333333332895062\t\n",
            "Epoch 4:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 1260/1260 [23:00<00:00,  1.10s/it]\n",
            "Training...:   0%|          | 0/140 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.3868875101090424\tmicro_f1:0.7604964351729601\n",
            "micro_f1s:0.8078902229344264\t0.7942973522930005\t0.6794995187212669\t0.5688073394030806\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...: 100%|██████████| 140/140 [00:56<00:00,  2.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss:0.04595222324132919\tmicro_f1:0.7009345794392523\n",
            "micro_f1s:0.7724137930523852\t0.7074829931471517\t0.6610169491042374\t0.3333333332895062\t\n",
            "Best F1: 0.715261958997722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xUstjQXe1EF"
      },
      "source": [
        "torch.save(model.state_dict(), \"model_state_{}\".format(seed))"
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}